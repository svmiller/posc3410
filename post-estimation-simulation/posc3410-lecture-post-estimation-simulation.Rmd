---
output: 
  stevetemplates::beamer:
    latex_engine: xelatex # use xelatex here instead! I recommend it, but this is minimal reprex
    dev: cairo_pdf # I typically comment this out  if latex_engine: pdflatex
    slide_level: 3 # I prefer this, but I won't force it on you.
title: "Post-estimation Simulation"
subtitle: POSC 3410  -- Quantitative Methods in Political Science
author: Steven V. Miller
institute: Department of Political Science
titlegraphic: "`r paste0(Sys.getenv('HOME'), '/Dropbox/clemson/watermarks/clemson-university-wordmark-orange-purple.png')`"
make149: true
mainfont: "Open Sans"
titlefont: "Titillium Web"
header-includes:
- \usepackage{dcolumn}
- \usepackage{booktabs}
- \usepackage{longtable}
- \usepackage{array}
- \usepackage{multirow}
- \usepackage{wrapfig}
- \usepackage{float}
- \usepackage{colortbl}
- \usepackage{pdflscape}
- \usepackage{tabu}
- \usepackage{threeparttable}
---



```{r setup, include=FALSE, cache=F, message=F, warning=F, results="hide"}
knitr::opts_chunk$set(cache=TRUE, warning=F, message=F, echo=FALSE, fig.width = 14, fig.height = 8.5)
knitr::opts_chunk$set(fig.path='figs/')
knitr::opts_chunk$set(cache.path='cache/')

knitr::opts_chunk$set(
                  fig.process = function(x) {
                      x2 = sub('-\\d+([.][a-z]+)$', '\\1', x)
                      if (file.rename(x, x2)) x2 else x
                      }
                  )
```


```{r loadstuff, include=FALSE}
knitr::opts_chunk$set(cache=TRUE)
options(knitr.kable.NA = '')
library(tidyverse)
library(stevemisc)
library(peacesciencer)
library(fixest)
library(kableExtra)
library(modelsummary)
library(patchwork)
library(cowplot)


options("modelsummary_format_numeric_latex" = "plain")
options(knitr.kable.NA = '')
```

```{r loaddata, cache=T, eval=T, echo=F, message=F, error=F, warning=F}
library(tidyverse)
library(stevemisc)
library(modelr)

VSG <- haven::read_dta("~/Dropbox/data/voter-study-group/2019-11/voter_2019Nov.dta")

VSG %>%
  select(systems_leader_2019Nov, systems_army_2019Nov, systems_democracy_2019Nov, 
         birthyr_2019Nov, gender_2019Nov, race_2019Nov, race_t_2019Nov, 
         ideo5_2019Nov, educ_2019Nov, bornagain_2019Nov, faminc_2019Nov, employment_2019Nov,
         ft_white_2019Nov, ft_asian_2019Nov, ft_black_2019Nov, ft_asian_2019Nov, ft_latino_2019Nov, ft_immig_2019Nov, ft_muslim_2019Nov,
         pid3_2019Nov, pid7_2019Nov) -> Data


Data %>% 
  mutate(armyruled = case_when(
    systems_army_2019Nov %in% c(1, 2) ~ 1,
    systems_army_2019Nov %in% c(3, 4) ~ 0
  ),
  armyrule = case_when(
    systems_army_2019Nov %in% c(1, 2, 3, 4) ~ (systems_army_2019Nov*-1)+5
  ),
  strongleaderd = case_when(
    systems_leader_2019Nov %in% c(1, 2) ~ 1,
    systems_leader_2019Nov %in% c(3, 4) ~ 0
  ),
  strongleader = case_when(
    systems_leader_2019Nov %in% c(1, 2, 3, 4) ~ (systems_leader_2019Nov*-1)+5
  ),
  havedemd = case_when(
    systems_democracy_2019Nov %in% c(1,2) ~ 0,
    systems_democracy_2019Nov %in% c(3,4) ~ 1
  ),
  havedem = ifelse(systems_democracy_2019Nov > 4, NA, systems_democracy_2019Nov)) -> Data

Data %>%
  mutate(white = ifelse(race_2019Nov == 1, 1, 0)) %>%
  filter(white == 1) -> Data

Data %>%
  mutate(therm_white = ft_white_2019Nov,
         therm_black = ft_black_2019Nov,
         therm_asian = ft_asian_2019Nov,
         therm_latino = ft_latino_2019Nov,
         therm_muslim = ft_muslim_2019Nov,
         therm_immig = ft_immig_2019Nov
  ) -> Data

Data %>%
  mutate_at(vars(contains("therm_")), ~ifelse(. > 100, NA, .)) -> Data

Data %>%
  mutate(prej_black = therm_white - therm_black,
         prejudice = therm_white - (((therm_black + therm_asian + therm_latino + therm_muslim))/4)) -> Data


Data %>% 
  mutate(age = 2019 - birthyr_2019Nov,
         female = case_when(gender_2019Nov == 1 ~ 0, gender_2019Nov == 2 ~ 1),
         collegeed = case_when(educ_2019Nov %in% c(1, 2, 3, 4) ~ 0,
                               educ_2019Nov %in% c(5,6) ~ 1),
         ideo = ifelse(ideo5_2019Nov > 5, NA, ideo5_2019Nov),
         unemployed = case_when(
           employment_2019Nov %in% c(3,4) ~ 1,
           employment_2019Nov %in% c(1,2, 5,6,7,8,9) ~ 0,
         ),
         pidcat = ifelse(pid3_2019Nov > 4, NA, pid3_2019Nov),
         dem = ifelse(pidcat == 1, 1, 0),
         gop = ifelse(pidcat == 2, 1, 0),
         pid7 = ifelse(pid7_2019Nov > 7, NA, pid7_2019Nov)) -> Data

Data %>%
  r2sd_at(c("ideo", "age", "prejudice", "pid7")) -> Data


M1 <- glm(strongleaderd ~ z_age + female + collegeed + z_ideo + unemployed + z_pid7 + z_prejudice,
          data = subset(Data, prejudice >= 0), family = binomial(link = "logit"))

M2 <- glm(armyruled ~ z_age + female + collegeed + z_ideo + unemployed + z_pid7 + z_prejudice,
          data = subset(Data, prejudice >= 0), family = binomial(link = "logit"))

M3 <- glm(havedemd ~ z_age + female + collegeed + z_ideo + unemployed + z_pid7 +  z_prejudice,
          data = subset(Data, prejudice >= 0), family = binomial(link = "logit"))


# M4 <- glm(strongleaderd ~ z_age + female + collegeed + z_ideo + unemployed + z_pid7*z_prejudice,
#           data = subset(Data, prejudice >= 0), family = binomial(link = "logit"))
# 
# M5 <- glm(armyruled ~ z_age + female + collegeed + z_ideo + unemployed + z_pid7*z_prejudice,
#           data = subset(Data, prejudice >= 0), family = binomial(link = "logit"))
# 
# M6 <- glm(havedemd ~ z_age + female + collegeed + z_ideo + unemployed + z_pid7*z_prejudice,
#           data = subset(Data, prejudice >= 0), family = binomial(link = "logit"))




Data %>% filter(prejudice %in% c(0, 25, 50, 100)) %>% 
  distinct(z_prejudice) %>% 
  arrange(z_prejudice) %>%
  pull(z_prejudice) -> z_prejudice_vals

Data %>%
  data_grid(.model = M1, z_prejudice = z_prejudice_vals,
            strongleaderd = 0, armyruled = 0, havedemd = 0) -> newdat_prejudice

Sims <- list()

Sims[[1]] <- get_sims(M1, newdat_prejudice, 1000, 8675309) %>% 
  mutate(cat = "Strong Leader", prejudice = rep(c(0, 25, 50, 100), 1000))
Sims[[2]] <- get_sims(M2, newdat_prejudice, 1000, 8675309) %>% 
  mutate(cat = "Army Rule", prejudice = rep(c(0, 25, 50, 100), 1000))
Sims[[3]] <- get_sims(M3, newdat_prejudice, 1000, 8675309) %>% 
  mutate(cat = "Oppose Democracy", prejudice = rep(c(0, 25, 50, 100), 1000))


```


# Introduction
### Goal for Today

*Provide intuitive quantities of interest from your regression.*

###

```r
library(tidyverse)    # for most things
library(stevemisc)    # for some various helper functions
library(modelr)       # for generating hypothetical data
library(modelsummary) # for regression tables
library(kableExtra)   # for some table formatting
```

### Readable Regression Tables

Remember: your analysis should be as easily interpretable as possible.

- I should get a preliminary glimpse of effect size from a regression.
- Your *y*-intercept should be meaningful.

Standardizing variables helps.

- Creates meaningful zeroes (i.e. the mean).
- Coefficients communicate magnitude changes in *x*.
- Standardizing by two SDs allows for easy comparison with binary predictors.

### Satisfy Your Audience

You need to relate your analysis to both me and your grandma.

- I will obviously know/care more about technical details.
- Grandma may not, but she may be a more important audience than me.

Her inquiries are likely be understandable. Examples:

- What's the expected tolerance of abortion for a religious Democrat?
- What's the increased probability of voting for a Republican for an increase of $20k in yearly income?

These are perfectly reasonable questions to ask of your analysis.

- If your presentation isn't prepared to answer her questions, you're not doing your job.

### Statistical Presentations

Statistical presentations should:

1. Convey precise estimates of quantities of interest.
2. Include reasonable estimates of *uncertainty* around those estimates.
3. Require little specialized knowledge to understand Nos. 1 and 2.
4. Not bombard the audience with superfluous information.

We will do this with post-estimation simulation using draws from a multivariate normal distribution (King et al. 2000).

# Estimating Uncertainty with Simulation
## Systematic and Stochastic Components
### Estimating Uncertainty with Simulation

Any statistical model has a stochastic and systematic component.

- **Stochastic**: $Y_i \sim f(y_i \thinspace | \thinspace \theta_i, \alpha )$
- **Systematic**:  $\theta_i = g(x_i, \beta)$

For a simple OLS model (i.e. a linear regression):

\begin{eqnarray}
Y_i &=& N(\mu_i, \thinspace \sigma^2)    \nonumber \\
\mu_i &=&  X_i\beta  \nonumber
\end{eqnarray}

### Understanding our Uncertainty

We have two types of uncertainty.

1. **Estimation uncertainty**
	-  Represents systematic components; can be reduced by increasing sample size.
2. **Fundamental uncertainty**
	- Represents stochastic component; exists no matter what (but can be modeled).

### Getting our Parameter Vector

We want a **simulated parameter vector**, denoted as:

$$
\hat{\gamma} \sim vec( \hat{\beta}, \hat{\alpha})
$$

Central limit theorem says with a large enough sample and bounded variance:

$$
\tilde{\gamma} \sim N( \hat{\gamma} , \hat{V}(\hat{\gamma}))
$$

In other words: distribution of quantities of interest will follow a multivariate normal distribution with mean equal to $\hat{\gamma}$, the simulated parameter vector.

### Another Way of Thinking About This

Subject to approximate regularity conditions and sample size:

- the conditional distribution of a quantity of interest, given the observed data, 
- can be approximated with a multivariate normal distribution with 
- parameters (coefficients, var-cov matrix) derived from the regression model. 

Gelman and Hill (2007) call this a "pseudo-Bayesian" approach.

- i.e. there are no prior assumptions of model parameters
- this approach papers over it because dependence on priors fades through large samples.

### Getting our Quantities of Interest

This is a mouthful! Let's break the process down step-by-step.

1. Run your regression. Look at your results.
2. Choose values of explanatory variable (as you see fit).
3. Grab the coefficient matrix and variance-covariance matrix.
4. Simulate outcomes by taking random draw from a multivariate normal distribution with those parameters.

Do this *m* times (typically *m* = 1000) to estimate full distribution of $Y_c$.

<!-- - Expected value $E(Y_c)$ = predicted value for linear models. It just averages over the fundamental uncertainty. -->

### A Brief Introduction of Terms

*Multivariate normal distribution*:  a generalization of the normal distribution to higher dimensions.

- every linear combination of its components has a normal distribution.
- used to describe correlated random variables each of which clusters around a mean value.

*Variance-covariance matrix*: a square matrix used for generating standard errors in regression

- I'll spare you the matrix algebra here.

# An Application with Prejudice and Support for Democracy (2019)
### Does Prejudice Decrease Support for (American) Democracy?

![](charlottesville-white-pride-rally.jpg)


### Prejudice and Support for Democracy

Miller and Davis (2021) argue that "white social prejudice" decreases support for democracy in the U.S.

- Prejudice is a rejection of the equal status of outgroups.
- Democracy is a representation of multiculturalism, broadly understood (i.e. pluralism).
- Democracy enfranchises groups of people that prejudice don't want empowered.

We expect white Americans who score high in prejudice are less receptive to democracy than those who score lower.

### Data (Voter Study Group, Nov. 2019)

*DVs*: how good/bad is it for the U.S. to have...

- a strong leader who does not have to deal with Congress or elections
- the army rule the government
- a democratic political system

All three are on 1-4 scale, collapsed to binary 0/1.

- *Model*: logistic regression on people who self-identify as white.

### Data (Voter Study Group, Nov. 2019)

*IVs*: a thermometer based approach to prejudice

- i.e. therm. rating for white people - mean therm. rating for black people, Latinos, Asians, and Muslims
- Scale ranges from 0 (no social prejudice) to 100 (maximum social prejudice)

*Controls*: respondent's age, sex (female), college education, ideology, unemployment, partisanship

###

```{r}
Data %>% filter(prejudice >=0) %>% ggplot(.,aes(prejudice)) + 
  theme_steve_web() +
  geom_density() +
  scale_x_continuous(breaks = seq(0, 100, by = 10)) +
  labs(x = "", y = "Density",
       title = "A Density Plot of White Social Prejudice",
       subtitle = "The data approximate an exponential distribution, with a noticeable right skew.",
       caption = "Data: Voter Study Group (Nov. 2019)")
```


###


```{r reg-table-1, echo=F, eval=T, fig.width = 14, fig.height = 8.5, warning = F, message = F, results="asis"}

modelsummary(list("Strong Leader" = M1,
                  "Army Rule" = M2,
                  "Oppose Democracy" = M3),
             longtable = TRUE,
             title = "The Effect of White Social Prejudice on Support for Democracy",
             gof_omit = "IC|F|Log.|R2$|R2",
             coef_map = c("z_prejudice" = "White Social Prejudice",
                          "z_age" = "Age",
                          "female" = "Female",
                          "collegeed" = "College Education",
                          "z_ideo" = "Ideology (L to C)",
                          "unemployed" = "Unemployed",
                          "z_pid7" = "Party ID (D to R)",
                          "dem" = "Democrat (vs. Ind/Other)",
                          "gop" = "Republican (vs. Ind/Other)"),
             stars = TRUE)  %>%
  row_spec(0, bold=TRUE) %>%
  kable_styling(font_size = 7) %>%
  row_spec(c(2), hline_after = TRUE) %>%
  row_spec(c( 1, 2), background="#eeeeee") 

```

### Something Nana Might Ask

*What is the probability of supporting a strong leader/army rule/opposing democracy by certain values of white social prejudice?*

- Let's see!

###

\scriptsize

```r
# find the z_prejudice values corresponding with raw values we want
Data %>% filter(prejudice %in% c(0, 25, 50, 100)) %>% 
  distinct(z_prejudice) %>% 
  arrange(z_prejudice) %>%
  pull(z_prejudice) -> z_prejudice_vals

# generating hypothetical data, everything else at typical value
# except for the prejudice values
Data %>%
  data_grid(.model = M1, z_prejudice = z_prejudice_vals,
            strongleaderd = 0, armyruled = 0, havedemd = 0) -> newdat_prejudice
```

\normalsize

###


```{r, echo=T}
Data %>%
  filter(prejudice %in% c(0, 25, 50, 100)) %>%
  distinct(prejudice, z_prejudice) %>%
  arrange(prejudice)
```

###

\scriptsize

```{r, echo=T}
newdat_prejudice %>%
  select(-strongleaderd:-havedemd)
```

\normalsize 

###

\scriptsize

```r
Sims <- list() # Store in a list

# For each model, run 1,000 simulations for these hypothetical data
# with reproducible seed
Sims[[1]] <- get_sims(M1, newdat_prejudice, 1000, 8675309) %>% 
  mutate(cat = "Strong Leader", prejudice = rep(c(0, 25, 50, 100), 1000))
  
Sims[[2]] <- get_sims(M2, newdat_prejudice, 1000, 8675309) %>% 
  mutate(cat = "Army Rule", prejudice = rep(c(0, 25, 50, 100), 1000))
  
Sims[[3]] <- get_sims(M3, newdat_prejudice, 1000, 8675309) %>% 
  mutate(cat = "Oppose Democracy", prejudice = rep(c(0, 25, 50, 100), 1000))
```

\normalsize

###

```{r}

do.call("rbind", Sims) %>%
  mutate(y = plogis(y),
         xlab = case_when(prejudice == 0 ~ "White Social Prejudice:\n0",
                          prejudice == 25 ~ "White Social Prejudice:\n25",
                          prejudice == 50 ~ "White Social Prejudice:\n50",
                          prejudice == 100 ~ "White Social Prejudice:\n100")) %>%
  mutate(xlab = fct_inorder(xlab)) %>%
  group_by(cat, xlab) %>%
  summarize(mean = mean(y),
            lwr = quantile(y, .025),
            upr = quantile(y, .975)) %>%
  ggplot(.,aes(xlab, y=mean, ymin=lwr, ymax=upr)) +
  facet_wrap(~cat) +
  geom_pointrange() +
  coord_flip() +
  theme_steve_web() +
  theme(axis.text = element_text(size = 11))  +
  labs(x = "", y = "Simulated Probability (with 95% Intervals)",
       title = "The Effect of White Social Prejudice on Attitudes about Democracy, Nov. 2019",
       subtitle = "In all cases, a min-to-max effect of white social prejudice results in a percentage change in the probability of an anti-democratic attitude by at least 200%.",
       caption = "Data: Nov. 2019 Voter Study Group")
```

# Conclusion
### Conclusion

Regression provides all-else-equal effect sizes across the range of the data.

- You can extract meaningful quantities of interest from regression output itself.
- Typically, you'll need more to answer substantive questions and provide meaningful quantities of interest.

Post-estimation simulation from a multivariate normal distribution does this.

- When you start doing this yourselves, be prepared to provide quantities of interest for your audience.
- Never forget: *you're trying to tell a story.* Tell it well.
